// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
//
// PageANN: Page-based Index Search Engine Header
// Copyright (c) 2025 Dingyi Kang <dingyikangosu@gmail.com>. All rights reserved.
// Licensed under the MIT license.

#pragma once
#include "common_includes.h"

#include "aligned_file_reader.h"
#include "concurrent_queue.h"
#include "neighbor.h"
#include "parameters.h"
#include "percentile_stats.h"
#include "pq.h"
#include "utils.h"
#include "windows_customizations.h"
#include "scratch.h"
#include "tsl/robin_map.h"
#include <tsl/sparse_map.h>
#include "tsl/robin_set.h"
#include <bitset>

#define FULL_PRECISION_REORDER_MULTIPLIER 3

namespace diskann
{

template <typename T, typename LabelT = uint32_t> class PQFlashIndex
{
  public:
    DISKANN_DLLEXPORT PQFlashIndex(std::shared_ptr<AlignedFileReader> &dataReader, diskann::Metric metric = diskann::Metric::L2);
    DISKANN_DLLEXPORT ~PQFlashIndex();

#ifdef EXEC_ENV_OLS
    DISKANN_DLLEXPORT int load(diskann::MemoryMappedFiles &files, uint32_t num_threads, const char *index_prefix);
#else
    /**
     * @brief Load page-based disk index and Product Quantization data into memory.
     *
     * This function initializes the PQFlashIndex by loading:
     * - Page graph topology and metadata
     * - Product Quantization (PQ) pivot centroids and compressed vectors
     * - Hash routing tables for fast entry point selection (optional)
     * - Medoid nodes for search initialization
     * - Aligned file readers for disk I/O
     *
     * @param num_threads Number of threads for parallel loading operations
     * @param index_prefix Path prefix for index files (graph, metadata, PQ data)
     * @param pq_path_prefix Path prefix for separate PQ data files
     * @param use_hash_routing If true, load and use hash-based routing for entry point selection
     * @param use_sampled_hash_routing If true, use sampled hash-based routing strategy
     * @param radius Reserved parameter for range search operations
     * @return 0 on success, -1 on failure
     *
     * @note This function must be called before any search operations
     * @note The index files must have been generated by build_page_graph()
     */
    DISKANN_DLLEXPORT int load(uint32_t num_threads, const char *index_prefix, const std::string &pq_path_prefix, const bool use_hash_routing, const bool use_sampled_hash_routing, const uint32_t radius);
#endif

#ifdef EXEC_ENV_OLS
    DISKANN_DLLEXPORT int load_from_separate_paths(diskann::MemoryMappedFiles &files, uint32_t num_threads,
                                                   const char *index_filepath, const char *pivots_filepath,
                                                   const char *compressed_filepath, const bool use_hash_routing, const bool use_sampled_hash_routing);
#else
    DISKANN_DLLEXPORT int load_from_separate_paths(uint32_t num_threads, const char *index_filepath,
                                                   const char *pivots_filepath, const char *compressed_filepath, const bool use_hash_routing, const bool use_sampled_hash_routing);
#endif

    /**
     * @brief Load frequently-accessed pages into memory cache.
     *
     * Loads the neighbor information for specified pages into an in-memory cache
     * to avoid disk I/O during search. This significantly improves search latency
     * for pages that are accessed frequently.
     *
     * @param page_list Vector of page IDs to cache (typically from generate_cache_list_from_sample_queries)
     *
     * @note The cache is stored in _nhood_cache map with page ID as key
     * @note Each cached entry contains: page neighbors, number of nodes in page, and page metadata
     */
    DISKANN_DLLEXPORT void load_cache_list(std::vector<uint32_t> &page_list);

#ifdef EXEC_ENV_OLS
    DISKANN_DLLEXPORT void generate_cache_list_from_sample_queries(MemoryMappedFiles &files, std::string sample_bin,
                                                                   uint64_t l_search, uint64_t beamwidth,
                                                                   uint64_t num_nodes_to_cache, uint32_t nthreads,
                                                                   std::vector<uint32_t> &node_list);
#else
    /**
     * @brief Identify frequently-accessed pages by running sample queries.
     *
     * Executes a set of representative queries and tracks which pages are visited most often.
     * The most frequently accessed pages are then cached in memory to reduce disk I/O during
     * actual search operations.
     *
     * @param sample_bin Path to binary file containing sample query vectors
     * @param l_search Search list size (L) to use for sample queries
     * @param beamwidth Beam width for parallel search during sampling
     * @param num_pages_to_cache Maximum number of pages to include in cache list
     * @param nthreads Number of threads for parallel sample query execution
     * @param page_list [Output] Vector to store page IDs sorted by access frequency (descending)
     * @param use_hash_routing If true, use hash-based routing for entry point selection in sample queries
     *
     * @note The output page_list can be passed to load_cache_list() to cache the pages
     * @note Sample queries should be representative of the actual query distribution
     */
    DISKANN_DLLEXPORT void generate_cache_list_from_sample_queries(std::string sample_bin, uint64_t l_search,
                                                                    uint64_t beamwidth, uint32_t num_pages_to_cache,
                                                                    uint32_t nthreads,
                                                                    std::vector<uint32_t> &page_list, bool use_hash_routing);
#endif

    /**
     * @brief Execute page-based approximate nearest neighbor search (primary search function).
     *
     * Performs beam search on the page graph to find approximate nearest neighbors:
     * 1. Compute PQ lookup tables for fast distance approximation
     * 2. Select entry point(s) using LSH or medoid nodes
     * 3. Execute beam search: maintain a priority queue of candidate pages, visit best candidates
     * 4. For each visited page: load neighbors (from cache or disk), evaluate vectors with PQ
     * 5. Optionally rerank top-K results using full-precision vectors
     *
     * @param query Query vector (must be aligned and of dimension _aligned_dim)
     * @param k_search Number of nearest neighbors to return (K)
     * @param l_search Search list size (L) - larger values improve recall but increase latency
     * @param rerank_num Number of top results to rerank with full precision (0 = no reranking)
     * @param res_ids [Output] Array to store IDs of K nearest neighbors (size: k_search)
     * @param res_dists [Output] Array to store distances to K nearest neighbors (size: k_search)
     * @param beam_width Number of pages to visit in parallel during beam search
     * @param use_reorder_data If true, use full-precision vectors for reranking
     * @param stats [Output] Optional statistics tracking (latency, I/O count, hops, cache hits)
     * @param use_hash_routing If true, use hash-based routing for entry point selection instead of medoid
     *
     * @note This is the main search function used on Windows platforms
     * @note Linux platforms typically use linux_page_search() for async I/O
     */
    DISKANN_DLLEXPORT void page_search(const T *query, const uint64_t k_search, const uint64_t l_search,
                                              uint64_t *res_ids, float *res_dists, const uint64_t beam_width,
                                              const bool use_reorder_data = false, QueryStats *stats = nullptr, const bool use_hash_routing = false);

    /** @brief page_search overload with label filtering support */
    DISKANN_DLLEXPORT void page_search(const T *query, const uint64_t k_search, const uint64_t l_search,
                                              uint64_t *res_ids, float *res_dists, const uint64_t beam_width,
                                              const bool use_filter, const LabelT &filter_label,
                                              const bool use_reorder_data = false, QueryStats *stats = nullptr, const bool use_hash_routing = false);

    /** @brief page_search overload with I/O limit to cap disk operations */
    DISKANN_DLLEXPORT void page_search(const T *query, const uint64_t k_search, const uint64_t l_search,
                                              uint64_t *res_ids, float *res_dists, const uint64_t beam_width,
                                              const uint32_t io_limit, const bool use_reorder_data = false,
                                              QueryStats *stats = nullptr, const bool use_hash_routing = false);

    /** @brief page_search overload with both label filtering and I/O limit */
    DISKANN_DLLEXPORT void page_search(const T *query, const uint64_t k_search, const uint64_t l_search,
                                              uint64_t *res_ids, float *res_dists, const uint64_t beam_width,
                                              const bool use_filter, const LabelT &filter_label,
                                              const uint32_t io_limit, const bool use_reorder_data = false,
                                              QueryStats *stats = nullptr, const bool use_hash_routing = false);

    /**
     * @brief Page-based ANN search for Linux platforms.
     *
     * Linux-specific version of page_search(). Note that despite the original name suggesting
     * async I/O pipelining, Linux AIO remains blocking in practice, so this function operates
     * similarly to the standard page_search() implementation.
     *
     * Algorithm workflow:
     * 1. PQ preprocessing and lookup table generation
     * 2. Entry point selection (hash routing or medoid)
     * 3. Beam search with priority queue
     * 4. Page neighbor loading (blocking I/O)
     * 5. Optional full-precision reranking
     *
     * @param query Query vector (aligned, dimension = _aligned_dim)
     * @param k_search Number of neighbors to return (K)
     * @param l_search Candidate list size (L)
     * @param res_ids [Output] IDs of K nearest neighbors
     * @param res_dists [Output] Distances to K nearest neighbors
     * @param beam_width Parallel beam search width
     * @param use_reorder_data Enable full-precision reranking
     * @param stats [Output] Search statistics (latency, I/O, hops)
     * @param use_hash_routing Use hash-based routing for entry point selection
     *
     * @note Used on Linux systems; functionally similar to page_search()
     */
    DISKANN_DLLEXPORT void linux_page_search(const T *query, const uint64_t k_search, const uint64_t l_search,
                                             uint64_t *res_ids, float *res_dists, const uint64_t beam_width,
                                             const bool use_reorder_data = false, QueryStats *stats = nullptr, const bool use_hash_routing = false);

    DISKANN_DLLEXPORT LabelT get_converted_label(const std::string &filter_label);

    DISKANN_DLLEXPORT uint64_t get_data_dim();

    std::shared_ptr<AlignedFileReader> &dataReader;

    DISKANN_DLLEXPORT diskann::Metric get_metric();

    /**
     * @brief Read node data from disk
     * @param node_ids List of node IDs to read
     * @param coord_buffers Pre-allocated buffers for coordinates (if null, don't copy)
     * @param nbr_buffers Pre-allocated buffers for neighbors
     * @return Vector of bool indicating read success for each node
     */
    DISKANN_DLLEXPORT std::vector<bool> read_nodes(const std::vector<uint32_t> &node_ids,
                                                   std::vector<T *> &coord_buffers,
                                                   std::vector<uint32_t *> &nbr_buffers);

    DISKANN_DLLEXPORT std::vector<bool> read_page_all_nodes(const std::vector<uint32_t> &page_ids,
                                                   std::vector<T *> &coord_buffers,
                                                   std::vector<uint32_t *> &nbr_buffers);
    
    DISKANN_DLLEXPORT std::vector<bool> read_page_nbrs(const std::vector<uint32_t> &page_ids, std::vector<std::vector<uint32_t>*> &nbr_buffers);
                                                   
    DISKANN_DLLEXPORT std::vector<std::uint8_t> get_pq_vector(std::uint64_t vid);
    DISKANN_DLLEXPORT uint64_t get_num_points();

  protected:
    DISKANN_DLLEXPORT void use_medoids_data_as_centroids();
    DISKANN_DLLEXPORT void setup_thread_data(uint64_t nthreads, uint64_t visited_reserve = 4096);

    DISKANN_DLLEXPORT void set_universal_label(const LabelT &label);

  private:
    DISKANN_DLLEXPORT inline bool point_has_label(uint32_t point_id, LabelT label_id);
    std::unordered_map<std::string, LabelT> load_label_map(std::basic_istream<char> &infile);
    DISKANN_DLLEXPORT void parse_label_file(std::basic_istream<char> &infile, size_t &num_pts_labels);
    DISKANN_DLLEXPORT void get_label_file_metadata(const std::string &fileContent, uint32_t &num_pts,
                                                   uint32_t &num_total_labels);
    DISKANN_DLLEXPORT void generate_random_labels(std::vector<LabelT> &labels, const uint32_t num_labels,
                                                  const uint32_t nthreads);
    void reset_stream_for_reading(std::basic_istream<char> &infile);

    // sector # on disk where node_id is present with in the graph part
    DISKANN_DLLEXPORT uint64_t get_node_sector(uint64_t node_id);

    // ptr to start of the node
    DISKANN_DLLEXPORT char *offset_to_node(char *sector_buf, uint64_t node_id);

    // returns region of `node_buf` containing [NNBRS][NBR_ID(uint32_t)]
    DISKANN_DLLEXPORT uint32_t *offset_to_node_nhood(char *node_buf);

    // returns region of `node_buf` containing [COORD(T)]
    DISKANN_DLLEXPORT T *offset_to_node_coords(char *node_buf);

    // index info for multi-node sectors
    // nhood of node `i` is in sector: [i / nnodes_per_sector]
    // offset in sector: [(i % nnodes_per_sector) * max_node_len]
    //
    // index info for multi-sector nodes
    // nhood of node `i` is in sector: [i * DIV_ROUND_UP(_max_node_len, SECTOR_LEN)]
    // offset in sector: [0]
    //
    // Common info
    // coords start at ofsset
    // #nbrs of node `i`: *(unsigned*) (offset + disk_bytes_per_point)
    // nbrs of node `i` : (unsigned*) (offset + disk_bytes_per_point + 1)

    uint64_t _max_node_len = 0;
    uint64_t _nnodes_per_sector = 0; // 0 for multi-sector nodes, >0 for multi-node sectors

    // Page-based graph parameters
    uint64_t _page_degree = 0;
    uint64_t _max_degree = 0;

    // Product Quantization cache parameters
    uint32_t _num_pq_cached_nodes = 0;
    bool _useID_pqIdx_map = false;
    bool _useID_pqIdx_array = false;
    bool _no_pq_cached = true;
    bool _all_pq_cached = false;
    uint8_t* _cached_pq_buff = nullptr;
    tsl::sparse_map<uint32_t, uint32_t> _nodeID_pqIdx_map; // Cache ratio < 50%
    std::vector<uint32_t> _nodeID_pqIdx_arr; // Cache ratio 50-100%

    // Hash routing data structures
    tsl::sparse_map<uint32_t, std::pair<uint32_t*, uint8_t>> _buckets; // Max 256 entries per bucket
    uint32_t* _sample_nodes_IDs_in_LSH = nullptr;
    float* _projectionMatrix = nullptr;
    int _numProjections;
    uint8_t _radius = 0;

    // Data used for searching with re-order vectors
    uint64_t _ndims_reorder_vecs = 0;
    uint64_t _reorder_data_start_sector = 0;
    uint64_t _nvecs_per_sector = 0;

    diskann::Metric metric = diskann::Metric::L2;

    // used only for inner product search to re-scale the result value
    // (due to the pre-processing of base during index build)
    float _max_base_norm = 0.0f;

    // data info
    uint64_t _num_points = 0;
    uint64_t _num_pages = 0;
    uint64_t _num_frozen_points = 0;
    uint64_t _frozen_location = 0;
    uint64_t _data_dim = 0;
    uint64_t _aligned_dim = 0;
    uint64_t _disk_bytes_per_point = 0; // Number of bytes

    std::string _disk_index_file;
    std::vector<std::pair<uint32_t, uint32_t>> _node_visit_counter;
    std::vector<std::pair<uint32_t, uint32_t>> _page_visit_counter;
    tsl::robin_set<uint32_t> _top_hops_pages;

    // PQ data
    // _n_chunks = # of chunks ndims is split into
    // data: char * _n_chunks
    // chunk_size = chunk size of each dimension chunk
    //so, in total, there are 256 (2^8) * numChuck centroids. and each centroid correspond to a float
    // pq_tables = float* [[2^8 * [chunk_size]] * _n_chunks]
    uint8_t *data = nullptr; //has manual delete
    uint64_t _n_chunks; //this is the number of PQ chunk -- size of compressed pq data
    FixedChunkPQTable _pq_table;

    // distance comparator
    std::shared_ptr<Distance<T>> _dist_cmp;
    std::shared_ptr<Distance<float>> _dist_cmp_float;

    // for very large datasets: we use PQ even for the disk resident index
    bool _use_disk_index_pq = false;
    uint64_t _disk_pq_n_chunks = 0;
    FixedChunkPQTable _disk_pq_table;

    // medoid/start info

    // graph has one entry point by default,
    // we can optionally have multiple starting points
    uint32_t *_medoids = nullptr; //has manual delete
    // defaults to 1
    size_t _num_medoids;
    // by default, it is empty. If there are multiple
    // centroids, we pick the medoid corresponding to the
    // closest centroid as the starting point of search
    float *_centroid_data = nullptr; //has manual delete

    // Cached pages data (neighbors and vector values)
    tsl::sparse_map<uint32_t, uint32_t> _cached_page_idx_map; // If cache ratio > 25%, use array instead
    uint32_t* _nhood_cache_buf = nullptr; // Has manual delete
    T *_coord_cache_buf = nullptr; // Has manual delete

    // thread-specific scratch
    ConcurrentQueue<SSDThreadData<T> *> _thread_data; //has manual delete
    uint64_t _max_nthreads;
    bool _load_flag = false;
    //bool _count_visited_nodes = false;
    bool _count_visited_pages = false;
    bool _getMostFrequentlyVisitedNodes = false;
    bool _reorder_data_exists = false;
    uint64_t _reoreder_data_offset = 0;

    // filter support
    uint32_t *_pts_to_label_offsets = nullptr; //has manual delete
    uint32_t *_pts_to_label_counts = nullptr; //has manual delete
    LabelT *_pts_to_labels = nullptr; //has manual delete
    std::unordered_map<LabelT, std::vector<uint32_t>> _filter_to_medoid_ids;
    bool _use_universal_label = false;
    LabelT _universal_filter_label;
    tsl::robin_set<uint32_t> _dummy_pts;
    tsl::robin_set<uint32_t> _has_dummy_pts;
    tsl::robin_map<uint32_t, uint32_t> _dummy_to_real_map;
    tsl::robin_map<uint32_t, std::vector<uint32_t>> _real_to_dummy_map;
    std::unordered_map<std::string, LabelT> _label_map;

#ifdef EXEC_ENV_OLS
    // Set to a larger value than the actual header to accommodate
    // any additions we make to the header. This is an outer limit
    // on how big the header can be.
    static const int HEADER_SIZE = defaults::SECTOR_LEN;
    char *getHeaderBytes();
#endif
};
} // namespace diskann
